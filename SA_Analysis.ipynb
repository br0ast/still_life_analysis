{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c3713c4-b258-4825-a595-cc262498c40a",
   "metadata": {},
   "source": [
    "# Deciphering Still Life Artworks with Linked Open Data - Code\n",
    "\n",
    "This notebook contains all the scripts to do the analysis described in the CHR2024 paper.\n",
    "\n",
    "Python version = Python 3.12.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c4035f-e440-4fb4-bb88-0e0284729b77",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba954621-9011-4939-8150-6494cfee9a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "import rdflib\n",
    "from rdflib import URIRef, BNode, Literal, Graph, Namespace, ConjunctiveGraph\n",
    "from rdflib.namespace import CSVW, DC, DCAT, DCTERMS, DOAP, FOAF, ODRL2, ORG, OWL, \\\n",
    "                           PROF, PROV, RDF, RDFS, SDO, SH, SKOS, SOSA, SSN, TIME, \\\n",
    "                           VOID, XMLNS, XSD\n",
    "from rdflib import namespace\n",
    "import pandas\n",
    "\n",
    "from rdflib import Graph, Namespace, RDFS\n",
    "from pymantic import sparql\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b79fb25-cad9-46d5-a273-a8c370348a2a",
   "metadata": {},
   "source": [
    "## Ancillary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e74ce4ac-b511-4e12-839f-ec1430f14184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_camel_case(input_string):\n",
    "    \"\"\"\n",
    "    Convert a string to CamelCase.\n",
    "\n",
    "    Args:\n",
    "    - input_string (str): The input string.\n",
    "\n",
    "    Returns:\n",
    "    - str: The CamelCase version of the input string.\n",
    "    \"\"\"\n",
    "    # Remove punctuation from the input string\n",
    "    input_string = input_string.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Split the input string into words using space and underscore as delimiters\n",
    "    words = re.split(r'[_\\s]+', input_string)\n",
    "\n",
    "    # Capitalize the first letter of each word (except the first word)\n",
    "    camel_words = [words[0].lower()] + [word.capitalize() for word in words[1:]]\n",
    "\n",
    "    # Join the words together to form the CamelCase string\n",
    "    camel_case_string = ''.join(camel_words)\n",
    "\n",
    "    return camel_case_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89c6a8e-5fde-4c02-8272-a1be5bd3dc86",
   "metadata": {},
   "source": [
    "## Loading HyperReal in RDFLIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ed46094-a625-45a2-8913-3a8de84e6259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Graph\n",
    "hr = Graph()\n",
    "\n",
    "# Parse the RDF data from the specified URL in Turtle format\n",
    "hr.parse(\"https://raw.githubusercontent.com/br0ast/simulationontology/main/KG/kg.ttl\", format=\"ttl\")\n",
    "\n",
    "# Define namespaces for easier access\n",
    "sim_on = \"https://w3id.org/simulation/ontology/\"\n",
    "\n",
    "sim_n = Namespace(sim_on)  # Replace with the actual URI\n",
    "hr.bind(\"sim\", sim_n)\n",
    "\n",
    "hrdata = \"https://w3id.org/simulation/data/\"\n",
    "hrd = Namespace(hrdata)\n",
    "hr.bind(\"hr\", hrd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da18cfec-1c08-4b7f-a33b-76566e1495af",
   "metadata": {},
   "source": [
    "### Extract disambiguations form HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdd8a4ed-4dda-4153-899d-dca832a554bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "setoftypes = set()\n",
    "\n",
    "# Iterate through objects with the predicate sim_n.hasSimulacrum\n",
    "for o in hr.objects(None, sim_n.hasSimulacrum, None):\n",
    "    # Retrieve labels for each object\n",
    "    for lab in hr.objects(o, RDFS.label, None):\n",
    "        # Check if the label contains \"(\"\n",
    "        if \"(\" in str(lab):\n",
    "            # Add the label to the set\n",
    "            setoftypes.add(str(lab))\n",
    "\n",
    "# Create a set to store types\n",
    "setoftypes2 = set()\n",
    "\n",
    "# Iterate over elements in setoftypes\n",
    "for el in setoftypes:\n",
    "    # Extract the type from the element\n",
    "    typ = el.split(\"(\")[1].split(\")\")[0]\n",
    "    setoftypes2.add(typ)\n",
    "\n",
    "# Remove types with spaces in the set\n",
    "setoftypes2 = {el for el in setoftypes2 if \" \" not in el}\n",
    "\n",
    "def combinewithtype(string):\n",
    "    \"\"\"\n",
    "    Combine a string with each type from setoftypes2.\n",
    "\n",
    "    Args:\n",
    "    - string (str): The input string.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of strings where each element is the input string combined with a type.\n",
    "    \"\"\"\n",
    "    # Create a list to store combined strings\n",
    "    listoftypes = []\n",
    "\n",
    "    # Iterate over types in setoftypes2\n",
    "    for typ in setoftypes2:\n",
    "        # Create a new string by combining the input string and the title-cased type\n",
    "        new_string = string + to_camel_case(typ).title()        \n",
    "        # Append the new string to the list\n",
    "        listoftypes.append(new_string)\n",
    "    # Return the list of combined strings\n",
    "    return listoftypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba00a004-d399-4ee9-8d14-b9f587c02c7f",
   "metadata": {},
   "source": [
    "# Common Names for Wikidata entity\n",
    "\n",
    "We extract both the english label of Wikidata entities and the \"common taxonomy name\" label, as some fruits/plants/flowers have their scientific name as the label, which does not match with HyperReal.\n",
    "\n",
    "We first import a csv with the \"depictedLabel\" (scientific name) and \"common\" (common taxonomy name) as columns. This csv was made by filtering the stillart.csv file in excel by keeping these two colums and removing the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d50ada71-0a64-4cb5-966c-df58100d89f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "common = pandas.read_csv(\"common_names.csv\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48d0591c-35a3-41a3-a730-e39562da7dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depictedLabel</th>\n",
       "      <th>common</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grey Partridge</td>\n",
       "      <td>Grey Partridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eurasian Eagle-owl</td>\n",
       "      <td>eurasian eagle owl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eurasian Eagle-owl</td>\n",
       "      <td>Eurasian Eagle-owl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eurasian Eagle-owl</td>\n",
       "      <td>Northern Eagle Owl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>house cat</td>\n",
       "      <td>Cat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        depictedLabel              common\n",
       "0      Grey Partridge      Grey Partridge\n",
       "1  Eurasian Eagle-owl  eurasian eagle owl\n",
       "2  Eurasian Eagle-owl  Eurasian Eagle-owl\n",
       "3  Eurasian Eagle-owl  Northern Eagle Owl\n",
       "4           house cat                 Cat"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce405883-376b-4ceb-9637-1eacbc2acf6d",
   "metadata": {},
   "source": [
    "## First Match Wikidata HyperReal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dc2090c-7e67-41f5-a8e2-289bd537529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_change = dict()\n",
    "dict_both = dict()\n",
    "nope = set()\n",
    "for i in range(len(common[\"depictedLabel\"])):\n",
    "    new =common[\"common\"][i]\n",
    "    orig =common[\"depictedLabel\"][i]\n",
    "    if orig.lower() != new.lower():\n",
    "        camel_orig = to_camel_case(orig)\n",
    "        camel_new = to_camel_case(new)\n",
    "        camel_orig_uri = URIRef(hrdata+camel_orig)\n",
    "        camel_new_uri = URIRef(hrdata+camel_new)\n",
    "        camel_orig_uri_flower = URIRef(hrdata+camel_orig+\"Flower\")\n",
    "        camel_new_uri_flower = URIRef(hrdata+camel_new+\"Flower\")\n",
    "\n",
    "        if (None, sim_n.hasSimulacrum, camel_orig_uri) in hr and (None, sim_n.hasSimulacrum, camel_new_uri) in hr:\n",
    "            if camel_orig not in dict_both:\n",
    "                dict_both[camel_orig] = set()\n",
    "            dict_both[camel_orig].add(camel_new)\n",
    "            if (None, sim_n.hasSimulacrum, camel_orig_uri_flower) in hr:\n",
    "                dict_both[camel_orig].add(camel_orig+\"Flower\")\n",
    "            if (None, sim_n.hasSimulacrum, camel_new_uri_flower) in hr:\n",
    "                dict_both[camel_orig].add(camel_new+\"Flower\")\n",
    "        elif (None, sim_n.hasSimulacrum, camel_orig_uri) in hr and (None, sim_n.hasSimulacrum, camel_new_uri) not in hr:\n",
    "            if (None, sim_n.hasSimulacrum, camel_orig_uri_flower) in hr:\n",
    "                if camel_orig not in dict_both:\n",
    "                    dict_both[camel_orig] = set()\n",
    "                dict_both[camel_orig].add(camel_orig+\"Flower\")\n",
    "            if (None, sim_n.hasSimulacrum, camel_new_uri_flower) in hr:\n",
    "                if camel_orig not in dict_both:\n",
    "                    dict_both[camel_orig] = set()\n",
    "                dict_both[camel_orig].add(camel_new+\"Flower\")\n",
    "        elif (None, sim_n.hasSimulacrum, camel_orig_uri) not in hr and (None, sim_n.hasSimulacrum, camel_new_uri) in hr:\n",
    "            if (None, sim_n.hasSimulacrum, camel_orig_uri_flower) in hr:\n",
    "                if camel_orig not in dict_change:\n",
    "                    dict_change[camel_orig] = set()\n",
    "                dict_change[camel_orig].add(camel_orig+\"Flower\")\n",
    "            if camel_orig not in dict_change:\n",
    "                dict_change[camel_orig] = set()\n",
    "            dict_change[camel_orig].add(camel_new)\n",
    "            if (None, sim_n.hasSimulacrum, camel_new_uri_flower) in hr:\n",
    "                if camel_orig not in dict_change:\n",
    "                    dict_change[camel_orig] = set()\n",
    "                dict_change[camel_orig].add(camel_new+\"Flower\")\n",
    "        elif (None, sim_n.hasSimulacrum, camel_orig_uri) not in hr and (None, sim_n.hasSimulacrum, camel_new_uri) not in hr:\n",
    "            if (None, sim_n.hasSimulacrum, camel_orig_uri_flower) in hr:\n",
    "                if camel_orig not in dict_change:\n",
    "                    dict_change[camel_orig] = set()\n",
    "                dict_change[camel_orig].add(camel_orig+\"Flower\")\n",
    "            if (None, sim_n.hasSimulacrum, camel_new_uri_flower) in hr:\n",
    "                if camel_orig not in dict_change:\n",
    "                    dict_change[camel_orig] = set()\n",
    "                dict_change[camel_orig].add(camel_new+\"Flower\")\n",
    "            nope.add(camel_orig_uri)\n",
    "        \n",
    "# dict change has the entities that do not match with HyperReal normally but match using the common taxonomy name\n",
    "# dict both has the entities that match in both their common name and normal label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08710e7-fefc-4b46-a047-cd71d42aea74",
   "metadata": {},
   "source": [
    "## Loading the still life art query csv result file\n",
    "\n",
    "To get this file you must use this query on wikidata: [https://w.wiki/AduD](https://w.wiki/AduD)\n",
    "\n",
    "The query was last run in May 2024, the results might be different if you redo it. If you want to replicate exactly the results of the paper, use the csv below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0e67d18-a3e7-4b95-9e36-1477b1fd67d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "still_art_query = pandas.read_csv(\"stillart.csv\") # if you rerun the query, update the file with the new csv downloaded from wikidata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d9eb77-6c01-4ae4-bee0-c3630b4ba633",
   "metadata": {},
   "source": [
    "## Loading previous mapping from HyperReal to Wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20cd87ad-c8eb-4255-8adc-2863e154700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wkh = pandas.read_csv(\"wikihyper.csv\", encoding=\"ISO-8859-1\", delimiter=\";\")\n",
    "wkhn = pandas.read_csv(\"wikihypernew.csv\", encoding=\"ISO-8859-1\", delimiter=\";\")\n",
    "wkhf =pandas.concat([wkh, wkhn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbd5604c-fb5a-4310-9bf1-417d7317737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wkhf = wkhf.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9d5fec-3eee-4150-92dd-dff554222d9b",
   "metadata": {},
   "source": [
    "## Adding new matches with semi-automatic decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92f39d39-9128-42ac-be5b-c2cc3d5652c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/figTree proposed does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/figTree proposed\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Accept? n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/figFruit proposed does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/figFruit proposed\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Accept? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/forkImplement proposed does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/forkImplement proposed\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Accept? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/appleTree proposed does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/appleTree proposed\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Accept? n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/appleFruit proposed does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/appleFruit proposed\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Accept? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/narcissusFlower proposed does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/narcissusFlower proposed\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Accept? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/narcissusPlant proposed does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/narcissusPlant proposed\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Accept? n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/bayTopography proposed does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/bayTopography proposed\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Accept? n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/plainTopography proposed does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/plainTopography proposed\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Accept? n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/stoolFurniture proposed does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/stoolFurniture proposed\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Accept? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/chestContainer proposed does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/chestContainer proposed\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Accept? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/pipeMusical proposed does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/pipeMusical proposed\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Accept? n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/pipeSmoking proposed does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/pipeSmoking proposed\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Accept? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/letterEpistle proposed does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/letterEpistle proposed\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Accept? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/matchFire proposed does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/matchFire proposed\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Accept? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/sealAnimal proposed does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/sealAnimal proposed\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Accept? n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/sealStamp proposed does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/sealStamp proposed\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Accept? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/bayTopography proposed does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/bayTopography proposed\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Accept? n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/hornMusical proposed does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/hornMusical proposed\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Accept? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/batAnimal proposed does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/batAnimal proposed\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Accept? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/broomPlant proposed does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/broomPlant proposed\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Accept? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/broomSweeping proposed does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/broomSweeping proposed\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Accept? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/perchFish proposed does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/perchFish proposed\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Accept? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/pikeFish proposed does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/pikeFish proposed\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Accept? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/pikeFish proposed does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/pikeFish proposed\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Accept? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/mustardPlant proposed does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/simulation/data/mustardPlant proposed\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Accept? y\n"
     ]
    }
   ],
   "source": [
    "not_there = []\n",
    "already_done = set()\n",
    "dict_change_2 = dict()\n",
    "types = set()\n",
    "for i in range(len(still_art_query[\"depicted\"])):\n",
    "    if still_art_query[\"depicted\"][i] not in already_done:\n",
    "        depi = still_art_query[\"depictedLabel\"][i]\n",
    "        depi = to_camel_case(depi)\n",
    "        there = False\n",
    "        if still_art_query[\"depicted\"][i] not in list(wkhf[\"wikidata\"]):\n",
    "            depinewlist = combinewithtype(depi)\n",
    "            uridepinewlist = [URIRef(hrdata+el) for el in depinewlist]\n",
    "            for depinew in uridepinewlist:\n",
    "                if (None, sim_n.hasSimulacrum, depinew) in hr:\n",
    "                    type_of = depinew.split(depi)[1]\n",
    "                    types.add(type_of)\n",
    "                    print(depinew + \" proposed\")\n",
    "                    answer = input(\"Accept?\")\n",
    "                    if answer == \"y\":\n",
    "                        dict_change_2[depi] = depinew.split(hrdata)[1]\n",
    "                        there = True\n",
    "        else:\n",
    "            there = True\n",
    "        if there is False:\n",
    "            not_there.append(still_art_query[\"depictedLabel\"][i])\n",
    "            already_done.add(still_art_query[\"depicted\"][i])\n",
    "        else:\n",
    "            already_done.add(still_art_query[\"depicted\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38e2b237-641b-4134-b672-ed499a4a1d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional change\n",
    "\n",
    "dict_change_2[\"bayLeaf\"] = \"bayLaurel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a79eb7-51d5-4cd0-af9e-58bbb5b95ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a555cda3-9f84-4b87-a360-cdd2ce06c7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_change_2b = dict()\n",
    "for el in dict_change_2:\n",
    "    newset = set()\n",
    "    newset.add(dict_change_2[el])\n",
    "    dict_change_2b[el] = newset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "115bac14-c74d-4f2d-b502-76c2ba757cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_change.update(dict_change_2b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b44829-6107-4ba8-864c-a6829e357768",
   "metadata": {},
   "source": [
    "## Final matching of potential interpretation wikidata-hyperreal\n",
    "\n",
    "**IMPORTANT**: for the next step it is necessary that HyperReal is also loaded locally in a GraphDB or Blazegraph server\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad051f5c-92b2-4403-ab85-580da8537958",
   "metadata": {},
   "outputs": [],
   "source": [
    "wk_hyper = dict()\n",
    "for i in range(len(wkhf[\"wikidata\"])):\n",
    "    w = list(wkhf[\"wikidata\"])[i]\n",
    "    if not pandas.isnull(wkhf[\"hyperreal\"][i]):\n",
    "        if w not in wk_hyper:\n",
    "            wk_hyper[w] = \"\"\n",
    "        wk_hyper[w] = wkhf[\"hyperreal\"][i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad27c816-598c-4f62-b8e0-659aadeebf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_address = \"http://LMKWDCH-NB-2300:7200/repositories/HyperReal\" # change this to the blazegraph/graphdb url\n",
    "server = sparql.SPARQLServer(server_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "807aaab6-4ca8-4628-9254-346a4ff473ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = set()\n",
    "depi_simu = {\"normal\":dict(), \"prevented\":dict(), \"healed\":dict()}\n",
    "for i in range(len(still_art_query[\"depicted\"])):\n",
    "    depi_w = still_art_query[\"depicted\"][i]\n",
    "    depi_l = still_art_query[\"depictedLabel\"][i]\n",
    "    depi_lc = to_camel_case(depi_l)\n",
    "    if depi_lc in depi_simu[\"normal\"]:\n",
    "        depi_simu[\"normal\"][depi_lc][\"artworks\"].add(still_art_query[\"painting\"][i])\n",
    "    if depi_lc in depi_simu[\"prevented\"]:\n",
    "        depi_simu[\"prevented\"][depi_lc][\"artworks\"].add(still_art_query[\"painting\"][i])\n",
    "    if depi_lc in depi_simu[\"healed\"]:\n",
    "        depi_simu[\"healed\"][depi_lc][\"artworks\"].add(still_art_query[\"painting\"][i])\n",
    "    if still_art_query[\"depicted\"][i] not in ad:\n",
    "        if depi_w in list(wkhf[\"wikidata\"]) and depi_w in wk_hyper:\n",
    "            simu = wk_hyper[depi_w]\n",
    "            result = server.query('''PREFIX kb: <https://w3id.org/simulation/data/>\n",
    "PREFIX sim: <https://w3id.org/simulation/ontology/>\n",
    "select ?simulation ?rc ?context where {\n",
    "    <'''+simu+'''> sim:isSimulacrumOf ?simulation .\n",
    "    ?simulation sim:hasRealityCounterpart ?rc ;\n",
    "                sim:hasContext ?context }''')\n",
    "            for res in result[\"results\"][\"bindings\"]:\n",
    "                if depi_lc not in depi_simu[\"normal\"]:\n",
    "                    depi_simu[\"normal\"][depi_lc] = {\"artworks\":set()}\n",
    "                if res[\"context\"][\"value\"] not in depi_simu[\"normal\"][depi_lc]:\n",
    "                    depi_simu[\"normal\"][depi_lc][res[\"context\"][\"value\"]] = set()\n",
    "                depi_simu[\"normal\"][depi_lc][\"artworks\"].add(still_art_query[\"painting\"][i])\n",
    "                depi_simu[\"normal\"][depi_lc][res[\"context\"][\"value\"]].add(res[\"rc\"][\"value\"])\n",
    "            result = server.query('''PREFIX kb: <https://w3id.org/simulation/data/>\n",
    "PREFIX sim: <https://w3id.org/simulation/ontology/>\n",
    "select ?simulation ?rc ?context where {\n",
    "    <'''+simu+'''> sim:isSimulacrumOf ?simulation .\n",
    "    ?simulation sim:preventedRealityCounterpart ?rc ;\n",
    "                sim:hasContext ?context }''')\n",
    "            for res in result[\"results\"][\"bindings\"]:\n",
    "                if depi_lc not in depi_simu[\"prevented\"]:\n",
    "                    depi_simu[\"prevented\"][depi_lc] = {\"artworks\":set()}\n",
    "                if res[\"context\"][\"value\"] not in depi_simu[\"prevented\"][depi_lc]:\n",
    "                    depi_simu[\"prevented\"][depi_lc][res[\"context\"][\"value\"]] = set()\n",
    "                depi_simu[\"prevented\"][depi_lc][\"artworks\"].add(still_art_query[\"painting\"][i])\n",
    "                depi_simu[\"prevented\"][depi_lc][res[\"context\"][\"value\"]].add(res[\"rc\"][\"value\"])\n",
    "            result = server.query('''PREFIX kb: <https://w3id.org/simulation/data/>\n",
    "PREFIX sim: <https://w3id.org/simulation/ontology/>\n",
    "select ?simulation ?rc ?context where {\n",
    "    <'''+simu+'''> sim:isSimulacrumOf ?simulation .\n",
    "    ?simulation sim:healedRealityCounterpart ?rc ;\n",
    "                sim:hasContext ?context }''')\n",
    "            for res in result[\"results\"][\"bindings\"]:\n",
    "                if depi_lc not in depi_simu[\"healed\"]:\n",
    "                    depi_simu[\"healed\"][depi_lc] = {\"artworks\":set()}\n",
    "                if res[\"context\"][\"value\"] not in depi_simu[\"healed\"][depi_lc]:\n",
    "                    depi_simu[\"healed\"][depi_lc][res[\"context\"][\"value\"]] = set()\n",
    "                depi_simu[\"healed\"][depi_lc][\"artworks\"].add(still_art_query[\"painting\"][i])\n",
    "                depi_simu[\"healed\"][depi_lc][res[\"context\"][\"value\"]].add(res[\"rc\"][\"value\"])\n",
    "            ad.add(still_art_query[\"depicted\"][i])\n",
    "        if depi_lc in dict_both:\n",
    "            simus = [depi_lc, list(dict_both[depi_lc])[0]]\n",
    "            #print(simus)\n",
    "            simus = [hrdata+sss for sss in simus]\n",
    "            for simu in simus:\n",
    "                result = server.query('''PREFIX kb: <https://w3id.org/simulation/data/>\n",
    "PREFIX sim: <https://w3id.org/simulation/ontology/>\n",
    "select ?simulation ?rc ?context where {\n",
    "    <'''+simu+'''> sim:isSimulacrumOf ?simulation .\n",
    "    ?simulation sim:hasRealityCounterpart ?rc ;\n",
    "                sim:hasContext ?context }''')\n",
    "                for res in result[\"results\"][\"bindings\"]:\n",
    "                    if depi_lc not in depi_simu[\"normal\"]:\n",
    "                        depi_simu[\"normal\"][depi_lc] = {\"artworks\":set()}\n",
    "                    if res[\"context\"][\"value\"] not in depi_simu[\"normal\"][depi_lc]:\n",
    "                        depi_simu[\"normal\"][depi_lc][res[\"context\"][\"value\"]] = set()\n",
    "                    depi_simu[\"normal\"][depi_lc][\"artworks\"].add(still_art_query[\"painting\"][i])\n",
    "                    depi_simu[\"normal\"][depi_lc][res[\"context\"][\"value\"]].add(res[\"rc\"][\"value\"])\n",
    "                result = server.query('''PREFIX kb: <https://w3id.org/simulation/data/>\n",
    "    PREFIX sim: <https://w3id.org/simulation/ontology/>\n",
    "    select ?simulation ?rc ?context where {\n",
    "        <'''+simu+'''> sim:isSimulacrumOf ?simulation .\n",
    "        ?simulation sim:preventedRealityCounterpart ?rc ;\n",
    "                    sim:hasContext ?context }''')\n",
    "                for res in result[\"results\"][\"bindings\"]:\n",
    "                    if depi_lc not in depi_simu[\"prevented\"]:\n",
    "                        depi_simu[\"prevented\"][depi_lc] = {\"artworks\":set()}\n",
    "                    if res[\"context\"][\"value\"] not in depi_simu[\"prevented\"][depi_lc]:\n",
    "                        depi_simu[\"prevented\"][depi_lc][res[\"context\"][\"value\"]] = set()\n",
    "                    depi_simu[\"prevented\"][depi_lc][\"artworks\"].add(still_art_query[\"painting\"][i])\n",
    "                    depi_simu[\"prevented\"][depi_lc][res[\"context\"][\"value\"]].add(res[\"rc\"][\"value\"])\n",
    "                result = server.query('''PREFIX kb: <https://w3id.org/simulation/data/>\n",
    "    PREFIX sim: <https://w3id.org/simulation/ontology/>\n",
    "    select ?simulation ?rc ?context where {\n",
    "        <'''+simu+'''> sim:isSimulacrumOf ?simulation .\n",
    "        ?simulation sim:healedRealityCounterpart ?rc ;\n",
    "                    sim:hasContext ?context }''')\n",
    "                for res in result[\"results\"][\"bindings\"]:\n",
    "                    if depi_lc not in depi_simu[\"healed\"]:\n",
    "                        depi_simu[\"healed\"][depi_lc] = {\"artworks\":set()}\n",
    "                    if res[\"context\"][\"value\"] not in depi_simu[\"healed\"][depi_lc]:\n",
    "                        depi_simu[\"healed\"][depi_lc][res[\"context\"][\"value\"]] = set()\n",
    "                    depi_simu[\"healed\"][depi_lc][\"artworks\"].add(still_art_query[\"painting\"][i])\n",
    "                    depi_simu[\"healed\"][depi_lc][res[\"context\"][\"value\"]].add(res[\"rc\"][\"value\"])\n",
    "            ad.add(still_art_query[\"depicted\"][i])\n",
    "        elif depi_lc in dict_change:\n",
    "            simus = dict_change[depi_lc]\n",
    "            simus = [hrdata+sss for sss in simus]\n",
    "            for simu in simus:\n",
    "                result = server.query('''PREFIX kb: <https://w3id.org/simulation/data/>\n",
    "PREFIX sim: <https://w3id.org/simulation/ontology/>\n",
    "select ?simulation ?rc ?context where {\n",
    "    <'''+simu+'''> sim:isSimulacrumOf ?simulation .\n",
    "    ?simulation sim:hasRealityCounterpart ?rc ;\n",
    "                sim:hasContext ?context }''')\n",
    "                for res in result[\"results\"][\"bindings\"]:\n",
    "                    if depi_lc not in depi_simu[\"normal\"]:\n",
    "                        depi_simu[\"normal\"][depi_lc] = {\"artworks\":set()}\n",
    "                    if res[\"context\"][\"value\"] not in depi_simu[\"normal\"][depi_lc]:\n",
    "                        depi_simu[\"normal\"][depi_lc][res[\"context\"][\"value\"]] = set()\n",
    "                    depi_simu[\"normal\"][depi_lc][\"artworks\"].add(still_art_query[\"painting\"][i])\n",
    "                    depi_simu[\"normal\"][depi_lc][res[\"context\"][\"value\"]].add(res[\"rc\"][\"value\"])\n",
    "                result = server.query('''PREFIX kb: <https://w3id.org/simulation/data/>\n",
    "    PREFIX sim: <https://w3id.org/simulation/ontology/>\n",
    "    select ?simulation ?rc ?context where {\n",
    "        <'''+simu+'''> sim:isSimulacrumOf ?simulation .\n",
    "        ?simulation sim:preventedRealityCounterpart ?rc ;\n",
    "                    sim:hasContext ?context }''')\n",
    "                for res in result[\"results\"][\"bindings\"]:\n",
    "                    if depi_lc not in depi_simu[\"prevented\"]:\n",
    "                        depi_simu[\"prevented\"][depi_lc] = {\"artworks\":set()}\n",
    "                    if res[\"context\"][\"value\"] not in depi_simu[\"prevented\"][depi_lc]:\n",
    "                        depi_simu[\"prevented\"][depi_lc][res[\"context\"][\"value\"]] = set()\n",
    "                    depi_simu[\"prevented\"][depi_lc][\"artworks\"].add(still_art_query[\"painting\"][i])\n",
    "                    depi_simu[\"prevented\"][depi_lc][res[\"context\"][\"value\"]].add(res[\"rc\"][\"value\"])\n",
    "                result = server.query('''PREFIX kb: <https://w3id.org/simulation/data/>\n",
    "    PREFIX sim: <https://w3id.org/simulation/ontology/>\n",
    "    select ?simulation ?rc ?context where {\n",
    "        <'''+simu+'''> sim:isSimulacrumOf ?simulation .\n",
    "        ?simulation sim:healedRealityCounterpart ?rc ;\n",
    "                    sim:hasContext ?context }''')\n",
    "                for res in result[\"results\"][\"bindings\"]:\n",
    "                    if depi_lc not in depi_simu[\"healed\"]:\n",
    "                        depi_simu[\"healed\"][depi_lc] = {\"artworks\":set()}\n",
    "                    if res[\"context\"][\"value\"] not in depi_simu[\"healed\"][depi_lc]:\n",
    "                        depi_simu[\"healed\"][depi_lc][res[\"context\"][\"value\"]] = set()\n",
    "                    depi_simu[\"healed\"][depi_lc][\"artworks\"].add(still_art_query[\"painting\"][i])\n",
    "                    depi_simu[\"healed\"][depi_lc][res[\"context\"][\"value\"]].add(res[\"rc\"][\"value\"])\n",
    "            ad.add(still_art_query[\"depicted\"][i])            \n",
    "        else:\n",
    "            ad.add(still_art_query[\"depicted\"][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ebfd1d-4cbf-4862-b619-0c84089c34d4",
   "metadata": {},
   "source": [
    "## IF YOU SKIPPED THE STEPS AND JUST WANT THE WIKIDATA MATCH FOR THE ANALYSIS RUN THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87658efa-d2a6-4c21-98db-27be4e4530a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open(\"still_art_int.p\",'rb')\n",
    "depi_simu = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a31d462-d1dd-437c-8530-8aa4572778a5",
   "metadata": {},
   "source": [
    "## FILTERING THE WIKIDATA QUERY TO ONLY INCLUDE PAINTINGS WITH AT LEAST 1 MATCH IN HYPERREAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d06fd608-0926-40db-a748-c3163a1fb90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3533\n",
      "4997\n"
     ]
    }
   ],
   "source": [
    "art_tot = set()\n",
    "for t in depi_simu:\n",
    "    for symb in depi_simu[t]:\n",
    "        for art in depi_simu[t][symb][\"artworks\"]:\n",
    "            art_tot.add(art)\n",
    "print(len(art_tot))\n",
    "print(len(set(still_art_query[\"painting\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d588eaf-a040-4b56-a919-bf1ae6f8a89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "still_art_filt = still_art_query[still_art_query['painting'].isin(art_tot)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bda9b92d-1287-4305-9314-1ca9e7bc5f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "still_art_filt =still_art_filt.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b554171-f750-4470-af1e-4eca1479fee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>painting</th>\n",
       "      <th>paintingLabel</th>\n",
       "      <th>depicted</th>\n",
       "      <th>depictedLabel</th>\n",
       "      <th>common</th>\n",
       "      <th>inception</th>\n",
       "      <th>countryLabel</th>\n",
       "      <th>iso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>http://www.wikidata.org/entity/Q153517</td>\n",
       "      <td>The Basket of Bread</td>\n",
       "      <td>http://www.wikidata.org/entity/Q7802</td>\n",
       "      <td>bread</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1926-01-01T00:00:00Z</td>\n",
       "      <td>Spain</td>\n",
       "      <td>ESP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>http://www.wikidata.org/entity/Q2270291</td>\n",
       "      <td>Basket of Fruit</td>\n",
       "      <td>http://www.wikidata.org/entity/Q201097</td>\n",
       "      <td>basket</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600-01-01T00:00:00Z</td>\n",
       "      <td>Italy</td>\n",
       "      <td>ITA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>http://www.wikidata.org/entity/Q152509</td>\n",
       "      <td>Luncheon on the Grass</td>\n",
       "      <td>http://www.wikidata.org/entity/Q843173</td>\n",
       "      <td>Pyrrhula</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1863-01-01T00:00:00Z</td>\n",
       "      <td>France</td>\n",
       "      <td>FRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>http://www.wikidata.org/entity/Q152509</td>\n",
       "      <td>Luncheon on the Grass</td>\n",
       "      <td>http://www.wikidata.org/entity/Q6578319</td>\n",
       "      <td>malleolus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1863-01-01T00:00:00Z</td>\n",
       "      <td>France</td>\n",
       "      <td>FRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>http://www.wikidata.org/entity/Q152509</td>\n",
       "      <td>Luncheon on the Grass</td>\n",
       "      <td>http://www.wikidata.org/entity/Q355304</td>\n",
       "      <td>watercourse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1863-01-01T00:00:00Z</td>\n",
       "      <td>France</td>\n",
       "      <td>FRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                 painting          paintingLabel  \\\n",
       "0      0   http://www.wikidata.org/entity/Q153517    The Basket of Bread   \n",
       "1      1  http://www.wikidata.org/entity/Q2270291        Basket of Fruit   \n",
       "2      3   http://www.wikidata.org/entity/Q152509  Luncheon on the Grass   \n",
       "3      4   http://www.wikidata.org/entity/Q152509  Luncheon on the Grass   \n",
       "4      5   http://www.wikidata.org/entity/Q152509  Luncheon on the Grass   \n",
       "\n",
       "                                  depicted depictedLabel common  \\\n",
       "0     http://www.wikidata.org/entity/Q7802         bread    NaN   \n",
       "1   http://www.wikidata.org/entity/Q201097        basket    NaN   \n",
       "2   http://www.wikidata.org/entity/Q843173      Pyrrhula    NaN   \n",
       "3  http://www.wikidata.org/entity/Q6578319     malleolus    NaN   \n",
       "4   http://www.wikidata.org/entity/Q355304   watercourse    NaN   \n",
       "\n",
       "              inception countryLabel  iso  \n",
       "0  1926-01-01T00:00:00Z        Spain  ESP  \n",
       "1  1600-01-01T00:00:00Z        Italy  ITA  \n",
       "2  1863-01-01T00:00:00Z       France  FRA  \n",
       "3  1863-01-01T00:00:00Z       France  FRA  \n",
       "4  1863-01-01T00:00:00Z       France  FRA  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "still_art_filt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7357278-9129-490c-bd15-66902658e4d8",
   "metadata": {},
   "source": [
    "## ODOR DATASET\n",
    "\n",
    "I have downloaded the instances_all.json file from the github: https://github.com/mathiaszinnen/odor-dataset/tree/main/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e9fb9e2-97f3-4260-b65d-0ac2acba4688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# We match the COCO annotations to the csv, to link every artwork with the detections of the computer vision algorithm\n",
    "f = open('instances_all.json')\n",
    "\n",
    "smelly_ann = json.load(f)\n",
    "smelly_df = pd.read_csv(\"https://raw.githubusercontent.com/mathiaszinnen/odor-dataset/main/data/meta.csv\")\n",
    "cat_id_label = dict()\n",
    "for cat in smelly_ann[\"categories\"]:\n",
    "    cat_id_label[cat[\"id\"]] = {\"label\":cat[\"name\"], \"supercategory\":[cat[\"supercategory\"]]}\n",
    "\n",
    "new_column = []\n",
    "for url in smelly_df[\"File Name\"]:\n",
    "    img_id = None\n",
    "    labels = []\n",
    "    for img in smelly_ann[\"images\"]:\n",
    "        if url == img[\"file_name\"]:\n",
    "            img_id = img[\"id\"]\n",
    "            break\n",
    "    if img_id:\n",
    "        for annotation in smelly_ann[\"annotations\"]:\n",
    "            if annotation[\"image_id\"] == img_id:\n",
    "                cat_id = annotation[\"category_id\"]\n",
    "                label = cat_id_label[cat_id][\"label\"]\n",
    "                labels.append(label)\n",
    "        labels = list(set(labels))\n",
    "        labels_string = \", \".join(labels)\n",
    "        new_column.append(labels_string)   \n",
    "    else:\n",
    "        new_column.append(\"\")\n",
    "\n",
    "smelly_df[\"detections\"] = new_column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "15eaaa61-6b9b-4672-a8ea-d771b0203f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "supercat_hr = {\"bird\": [\"animal\", \"bird\"], \"clothing\":[\"clothing\"], \"fish\": [\"animal\", \"fish\"],\n",
    "               \"flower\":[\"flower\"], \"fruit\":[\"fruit\"], \"insect\":[\"insect\"], \"lamp\":[\"lamp\"],\n",
    "               \"lighting\":[\"lighting\"], \"vegetable\":[\"plant\"]} ### For the disambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d897444c-9ee2-4d3b-a986-f783359873be",
   "metadata": {},
   "source": [
    "### MATCH ODOR HYPERREAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d39861e5-afa3-4c9b-b926-bcfae1223990",
   "metadata": {},
   "outputs": [],
   "source": [
    "smelly_hr = dict()\n",
    "for el in cat_id_label:\n",
    "    el_uri = URIRef(hrdata+to_camel_case(cat_id_label[el][\"label\"]))\n",
    "    if (None, sim_n.hasSimulacrum, el_uri) in hr:\n",
    "        if cat_id_label[el][\"label\"] not in smelly_hr:\n",
    "            smelly_hr[cat_id_label[el][\"label\"]] = []\n",
    "        smelly_hr[cat_id_label[el][\"label\"]].append(el_uri)\n",
    "    for category in cat_id_label[el][\"supercategory\"]:\n",
    "        if category in supercat_hr:\n",
    "            newcategories = supercat_hr[category]\n",
    "            for newcat in newcategories:\n",
    "                newel = cat_id_label[el][\"label\"] + \" \" + newcat\n",
    "                neweluri = URIRef(hrdata+to_camel_case(newel))\n",
    "                if (None, sim_n.hasSimulacrum, neweluri) in hr:\n",
    "                    if cat_id_label[el][\"label\"] not in smelly_hr:\n",
    "                        smelly_hr[cat_id_label[el][\"label\"]] = []  \n",
    "                    smelly_hr[cat_id_label[el][\"label\"]].append(neweluri)\n",
    "smelly_hr[\"snake\"].append(URIRef(hrdata+\"serpent\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b2543b7d-0dcf-4400-9fc4-2cb11bcbf4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'still life'\n",
    "columns_to_check = ['Title', 'Iconography', 'Description',\"Keywords\"]  # List of columns to check\n",
    "\n",
    "filtered_smelly_df = smelly_df[smelly_df[columns_to_check].apply(lambda row: row.str.contains(keyword, na=False)).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "106c40aa-b7e9-4d37-95f1-b412de41d574",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_smelly_df =filtered_smelly_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de97b4a8-a02b-4794-b8e4-e5ed0b64bb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will generate warning but only because .query is shared by rdflib and pymantiq, you can ignore them\n",
    "ad_smelly = set()\n",
    "depi_smelly_simu = {\"normal\":dict(), \"prevented\":dict(), \"healed\":dict()}\n",
    "for i in range(len(filtered_smelly_df[\"File Name\"])):\n",
    "    detections = filtered_smelly_df[\"detections\"][i].split(\", \")\n",
    "    for det in detections:\n",
    "        if det in depi_smelly_simu[\"normal\"]:\n",
    "            depi_smelly_simu[\"normal\"][det][\"artworks\"].add(filtered_smelly_df[\"File Name\"][i])\n",
    "        if det in depi_smelly_simu[\"prevented\"]:\n",
    "            depi_smelly_simu[\"prevented\"][det][\"artworks\"].add(filtered_smelly_df[\"File Name\"][i])\n",
    "        if det in depi_smelly_simu[\"healed\"]:\n",
    "            depi_smelly_simu[\"healed\"][det][\"artworks\"].add(filtered_smelly_df[\"File Name\"][i])\n",
    "        if det not in ad_smelly:\n",
    "            if det in smelly_hr:\n",
    "                for simu in smelly_hr[det]:\n",
    "                    result = server.query('''PREFIX kb: <https://w3id.org/simulation/data/>\n",
    "        PREFIX sim: <https://w3id.org/simulation/ontology/>\n",
    "        select ?simulation ?rc ?context where {\n",
    "            <'''+simu+'''> sim:isSimulacrumOf ?simulation .\n",
    "            ?simulation sim:hasRealityCounterpart ?rc ;\n",
    "                        sim:hasContext ?context }''')\n",
    "                    for res in result[\"results\"][\"bindings\"]:\n",
    "                        if det not in depi_smelly_simu[\"normal\"]:\n",
    "                            depi_smelly_simu[\"normal\"][det] = {\"artworks\":set()}\n",
    "                        if res[\"context\"][\"value\"] not in depi_smelly_simu[\"normal\"][det]:\n",
    "                            depi_smelly_simu[\"normal\"][det][res[\"context\"][\"value\"]] = set()\n",
    "                        depi_smelly_simu[\"normal\"][det][\"artworks\"].add(filtered_smelly_df[\"File Name\"][i])\n",
    "                        depi_smelly_simu[\"normal\"][det][res[\"context\"][\"value\"]].add(res[\"rc\"][\"value\"])\n",
    "                    result = server.query('''PREFIX kb: <https://w3id.org/simulation/data/>\n",
    "        PREFIX sim: <https://w3id.org/simulation/ontology/>\n",
    "        select ?simulation ?rc ?context where {\n",
    "            <'''+simu+'''> sim:isSimulacrumOf ?simulation .\n",
    "            ?simulation sim:hasRealityCounterpart ?rc ;\n",
    "                        sim:hasContext ?context }''')\n",
    "                    for res in result[\"results\"][\"bindings\"]:\n",
    "                        if det not in depi_smelly_simu[\"prevented\"]:\n",
    "                            depi_smelly_simu[\"prevented\"][det] = {\"artworks\":set()}\n",
    "                        if res[\"context\"][\"value\"] not in depi_smelly_simu[\"prevented\"][det]:\n",
    "                            depi_smelly_simu[\"prevented\"][det][res[\"context\"][\"value\"]] = set()\n",
    "                        depi_smelly_simu[\"prevented\"][det][\"artworks\"].add(filtered_smelly_df[\"File Name\"][i])\n",
    "                        depi_smelly_simu[\"prevented\"][det][res[\"context\"][\"value\"]].add(res[\"rc\"][\"value\"])\n",
    "                    result = server.query('''PREFIX kb: <https://w3id.org/simulation/data/>\n",
    "        PREFIX sim: <https://w3id.org/simulation/ontology/>\n",
    "        select ?simulation ?rc ?context where {\n",
    "            <'''+simu+'''> sim:isSimulacrumOf ?simulation .\n",
    "            ?simulation sim:hasRealityCounterpart ?rc ;\n",
    "                        sim:hasContext ?context }''')\n",
    "                    for res in result[\"results\"][\"bindings\"]:\n",
    "                        if det not in depi_smelly_simu[\"healed\"]:\n",
    "                            depi_smelly_simu[\"healed\"][det] = {\"artworks\":set()}\n",
    "                        if res[\"context\"][\"value\"] not in depi_smelly_simu[\"healed\"][det]:\n",
    "                            depi_smelly_simu[\"healed\"][det][res[\"context\"][\"value\"]] = set()\n",
    "                        depi_smelly_simu[\"healed\"][det][\"artworks\"].add(filtered_smelly_df[\"File Name\"][i])\n",
    "                        depi_smelly_simu[\"healed\"][det][res[\"context\"][\"value\"]].add(res[\"rc\"][\"value\"])\n",
    "                    ad_smelly.add(det)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d56e6b-b2a9-4189-81c7-424913295ceb",
   "metadata": {},
   "source": [
    "### IF YOU WANT TO SKIP THE PREVIOUS STEPS! IMPORT THIS:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ae7cea94-5153-47c5-834d-ee117c519e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open(\"smelly_int.p\",'rb')\n",
    "depi_smelly_simu = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06660134-67af-49e9-a431-b592dbf53806",
   "metadata": {},
   "source": [
    "### CONTINUE AFTER SKIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3ffbd860-76b7-4d9f-b13a-3125a856c8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478\n"
     ]
    }
   ],
   "source": [
    "smelly_symb_art = set()\n",
    "for i in range(len(filtered_smelly_df[\"File Name\"])):\n",
    "    art = filtered_smelly_df[\"File Name\"][i]\n",
    "    for det in filtered_smelly_df[\"detections\"][i].split(\", \"):\n",
    "        if det in smelly_hr:\n",
    "            smelly_symb_art.add(art)\n",
    "            break\n",
    "print(len(smelly_symb_art))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14358c58-65a5-4cac-855e-b0ffe7d4ca8a",
   "metadata": {},
   "source": [
    "## RQ1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f356491f-6677-4ff9-8b46-809f45fedfb1",
   "metadata": {},
   "source": [
    "### Percentage of Christian Contexts in Wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "15a0d148-d124-4fc7-9c93-c894a6434711",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = set()\n",
    "for t in depi_simu:\n",
    "    for symb in depi_simu[t]:\n",
    "        ctxs = list(depi_simu[t][symb].keys())\n",
    "        ctxs.remove(\"artworks\")\n",
    "        for el in ctxs:\n",
    "            contexts.add(el)\n",
    "ctx_count = dict()\n",
    "for cont in contexts:\n",
    "    ctx_count[cont]= set()\n",
    "    for t in depi_simu:\n",
    "        for symb in depi_simu[t]:\n",
    "            if cont in depi_simu[t][symb]:\n",
    "                for art in depi_simu[t][symb][\"artworks\"]:\n",
    "                    ctx_count[cont].add(art)\n",
    "ctx_count_numb = dict()\n",
    "for el in ctx_count:\n",
    "    ctx_count_numb[el] =len(ctx_count[el])\n",
    "ctx_count_numb_perc = dict()\n",
    "for el in ctx_count_numb:\n",
    "    ctx_count_numb_perc[el] = round(ctx_count_numb[el]*100/3533, 3)\n",
    "sorted_ctx_count_numb = sorted(ctx_count_numb.items(), key=lambda item: item[1], reverse=True)\n",
    "sorted_ctx_count_numb_perc = sorted(ctx_count_numb_perc.items(), key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45a67542-cb80-4650-8c24-c3b86918d8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://w3id.org/simulation/data/generalOrUnknown', 99.123),\n",
       " ('https://w3id.org/simulation/data/christian', 84.914),\n",
       " ('https://w3id.org/simulation/data/heraldic', 67.62),\n",
       " ('https://w3id.org/simulation/data/grecoRoman', 63.431),\n",
       " ('https://w3id.org/simulation/data/greek', 53.948),\n",
       " ('https://w3id.org/simulation/data/chinese', 47.665),\n",
       " ('https://w3id.org/simulation/data/jewish', 43.787),\n",
       " ('https://w3id.org/simulation/data/roman', 37.617),\n",
       " ('https://w3id.org/simulation/data/egyptian', 36.343),\n",
       " ('https://w3id.org/simulation/data/buddhist', 35.126)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_ctx_count_numb_perc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a4339b-ab44-4ac0-af12-434f23edb793",
   "metadata": {},
   "source": [
    "### Percentage of Christian Context in ODOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ebb96739-5ffb-458f-a6c6-f08a76f61d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = set()\n",
    "for t in depi_smelly_simu:\n",
    "    for symb in depi_smelly_simu[t]:\n",
    "        ctxs = list(depi_smelly_simu[t][symb].keys())\n",
    "        ctxs.remove(\"artworks\")\n",
    "        for el in ctxs:\n",
    "            contexts.add(el)\n",
    "ctx_count = dict()\n",
    "for cont in contexts:\n",
    "    ctx_count[cont]= set()\n",
    "    for t in depi_smelly_simu:\n",
    "        for symb in depi_smelly_simu[t]:\n",
    "            if cont in depi_smelly_simu[t][symb]:\n",
    "                for art in depi_smelly_simu[t][symb][\"artworks\"]:\n",
    "                    ctx_count[cont].add(art)\n",
    "ctx_count_numb = dict()\n",
    "for el in ctx_count:\n",
    "    ctx_count_numb[el] =len(ctx_count[el])\n",
    "ctx_count_numb_perc = dict()\n",
    "for el in ctx_count_numb:\n",
    "    ctx_count_numb_perc[el] = round(ctx_count_numb[el]*100/478, 3)\n",
    "sorted_ctx_count_numb = sorted(ctx_count_numb.items(), key=lambda item: item[1], reverse=True)\n",
    "sorted_ctx_count_numb_perc = sorted(ctx_count_numb_perc.items(), key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a58be90-3c6d-47e9-8ea7-f90ace287d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://w3id.org/simulation/data/generalOrUnknown', 100.0),\n",
       " ('https://w3id.org/simulation/data/christian', 93.305),\n",
       " ('https://w3id.org/simulation/data/heraldic', 81.172),\n",
       " ('https://w3id.org/simulation/data/grecoRoman', 75.732),\n",
       " ('https://w3id.org/simulation/data/greek', 75.105),\n",
       " ('https://w3id.org/simulation/data/jewish', 70.921),\n",
       " ('https://w3id.org/simulation/data/chinese', 69.874),\n",
       " ('https://w3id.org/simulation/data/egyptian', 65.272),\n",
       " ('https://w3id.org/simulation/data/japanese', 56.276),\n",
       " ('https://w3id.org/simulation/data/celtic', 51.255)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_ctx_count_numb_perc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00deb62e-13bb-41dd-97fb-afb4bcdc2253",
   "metadata": {},
   "source": [
    "### Percentage of Christian Context SAMPLE\n",
    "\n",
    "If you want to obtain a different sample, you must query IICONGRAPH with this query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b297b734-fc10-4b92-a041-03e94ca888b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_for_sample = '''\n",
    "PREFIX sim: <https://w3id.org/simulation/ontology/>\n",
    "PREFIX icon: <https://w3id.org/icon/ontology/>\n",
    "select ?art (GROUP_CONCAT(distinct ?ctx; SEPARATOR=\" @ \") as ?ctxs) where { \n",
    "\t?art icon:iconographicallyDepicts ?simulation .\n",
    "    ?simulation sim:hasContext ?ctx .\n",
    "} GROUP BY ?art ORDER BY RAND() LIMIT 3533'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b912c15a-6946-42bb-8e20-b37c01af6503",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample3533 = pd.read_csv(\"sample3533.tsv\", delimiter=\"\\t\")\n",
    "ctx_count_sample = dict()\n",
    "for i in range(len(sample3533[\"?art\"])):\n",
    "    ctxs = sample3533[\"?ctxs\"][i].split(\" @ \")\n",
    "    ctxs = [el for el in ctxs if len(el) > 3]\n",
    "    for ct in ctxs:\n",
    "        if ct not in ctx_count_sample:\n",
    "            ctx_count_sample[ct] = set()\n",
    "        ctx_count_sample[ct].add(sample3533[\"?art\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "51a9c447-9c4a-44ec-9ad2-3a504f049520",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_count_sample_numb = dict()\n",
    "for el in ctx_count_sample:\n",
    "    ctx_count_sample_numb[el] =len(ctx_count_sample[el])\n",
    "ctx_count_sample_numb_perc = dict()\n",
    "for el in ctx_count_sample_numb:\n",
    "    ctx_count_sample_numb_perc[el] = round(ctx_count_sample_numb[el]*100/3533, 3)\n",
    "sorted_ctx_count_sample_numb = sorted(ctx_count_sample_numb.items(), key=lambda item: item[1], reverse=True)\n",
    "sorted_ctx_count_sample_numb_perc = sorted(ctx_count_sample_numb_perc.items(), key=lambda item: item[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b2e4e978-e40d-4cec-a962-26b6da19aba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://w3id.org/simulation/data/generalOrUnknown', 85.31),\n",
       " ('https://w3id.org/simulation/data/christian', 43.504),\n",
       " ('https://w3id.org/simulation/data/heraldic', 32.607),\n",
       " ('https://w3id.org/simulation/data/grecoRoman', 22.276),\n",
       " ('https://w3id.org/simulation/data/jewish', 21.596),\n",
       " ('https://w3id.org/simulation/data/chinese', 20.549),\n",
       " ('https://w3id.org/simulation/data/greek', 19.304),\n",
       " ('https://w3id.org/simulation/data/egyptian', 18.653),\n",
       " ('https://w3id.org/simulation/data/hindu', 18.256),\n",
       " ('https://w3id.org/simulation/data/buddhist', 16.7)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_ctx_count_sample_numb_perc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a918c79b-4308-4456-b043-54426a305e45",
   "metadata": {},
   "source": [
    "## RQ2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaa169c-03c9-4d7e-ac20-0d082050e259",
   "metadata": {},
   "source": [
    "### Timesplit and correlation Wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c92715f-346a-4c3d-a389-37de7bd87921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Step 3: Define the date ranges and filter the DataFrame\n",
    "still_art_filt['inception'] = still_art_filt['inception'].apply(lambda x: datetime.strptime(x, '%Y-%m-%dT%H:%M:%SZ') if pd.notna(x) and \"wikidata\" not in str(x) else None)\n",
    "\n",
    "# Step 3: Define the date ranges\n",
    "\n",
    "date_before_1600 = datetime(1600, 1, 1)\n",
    "date_1600 = datetime(1600, 1, 1)\n",
    "date_1700 = datetime(1700, 1, 1)\n",
    "date_1800 = datetime(1800, 1, 1)\n",
    "date_1900 = datetime(1900, 1, 1)\n",
    "\n",
    "# Step 4: Filter the DataFrame\n",
    "before_1600 = still_art_filt[still_art_filt['inception'] < date_before_1600]\n",
    "between_1600_and_1699 = still_art_filt[(still_art_filt['inception'] >= date_1600) & (still_art_filt['inception'] < date_1700)]\n",
    "between_1700_and_1799 = still_art_filt[(still_art_filt['inception'] >= date_1700) & (still_art_filt['inception'] < date_1800)]\n",
    "between_1800_and_1899 = still_art_filt[(still_art_filt['inception'] >= date_1800) & (still_art_filt['inception'] < date_1900)]\n",
    "after_1900 = still_art_filt[still_art_filt['inception'] >= date_1900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "413b4378-b9b6-4f68-9b23-9e4e1de49172",
   "metadata": {},
   "outputs": [],
   "source": [
    "art_before_1600 = list(before_1600[\"painting\"])\n",
    "art_between_1600_and_1699 = list(between_1600_and_1699[\"painting\"])\n",
    "art_between_1700_and_1799 = list(between_1700_and_1799[\"painting\"])\n",
    "art_between_1800_and_1899 = list(between_1800_and_1899[\"painting\"])\n",
    "art_after_1900 = list(after_1900[\"painting\"])\n",
    "periods = [art_before_1600,\n",
    "art_between_1600_and_1699,\n",
    "art_between_1700_and_1799,\n",
    "art_between_1800_and_1899,\n",
    "art_after_1900]\n",
    "symb_meanings_16th_century = dict()\n",
    "symb_meanings_17th_century = dict()\n",
    "symb_meanings_18th_century = dict()\n",
    "symb_meanings_19th_century = dict()\n",
    "symb_meanings_20_21th_century = dict()\n",
    "dizz_sm = [symb_meanings_16th_century,\n",
    "symb_meanings_17th_century,\n",
    "symb_meanings_18th_century,\n",
    "symb_meanings_19th_century,\n",
    "symb_meanings_20_21th_century]\n",
    "for i in range(len(dizz_sm)):    \n",
    "    for t in depi_simu:\n",
    "        for depi in depi_simu[t]:\n",
    "            for ctx in depi_simu[t][depi]:\n",
    "                if ctx != \"artworks\":\n",
    "                    for meaning in depi_simu[t][depi][ctx]:\n",
    "                        meaning_short = meaning.split(hrdata)[1]\n",
    "                        if meaning_short not in dizz_sm[i]:\n",
    "                            dizz_sm[i][meaning_short] = set()\n",
    "                        for art in depi_simu[t][depi][\"artworks\"]:\n",
    "                            if art in periods[i]:\n",
    "                                dizz_sm[i][meaning_short].add(art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "50cf245c-05c4-4fd0-8d7b-76c1cc8b6609",
   "metadata": {},
   "outputs": [],
   "source": [
    "smb18 = dict()\n",
    "for k in symb_meanings_16th_century:\n",
    "    if k not in smb18:\n",
    "        smb18[k] = symb_meanings_16th_century[k]\n",
    "    else:\n",
    "        smb18[k] = smb18[k].union(symb_meanings_16th_century[k])\n",
    "for k in symb_meanings_17th_century:\n",
    "    if k not in smb18:\n",
    "        smb18[k] = symb_meanings_17th_century[k]\n",
    "    else:\n",
    "        smb18[k] = smb18[k].union(symb_meanings_17th_century[k])\n",
    "for k in symb_meanings_18th_century:\n",
    "    if k not in smb18:\n",
    "        smb18[k] = symb_meanings_18th_century[k]\n",
    "    else:\n",
    "        smb18[k] = smb18[k].union(symb_meanings_18th_century[k])\n",
    "\n",
    "\n",
    "sma18 = dict()\n",
    "a18 = [symb_meanings_19th_century, symb_meanings_20_21th_century]\n",
    "for diz in a18: \n",
    "    for k in diz:\n",
    "        if k not in sma18:\n",
    "            sma18[k] = diz[k]\n",
    "        else:\n",
    "            sma18[k] = sma18[k].union(diz[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "750dd3d2-e80e-412c-8411-2c6f98788c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "totartb18 = 2073\n",
    "totarta18 = 1213"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a3c68d11-c70a-496f-8a66-654d8d1f3412",
   "metadata": {},
   "outputs": [],
   "source": [
    "smb18p = dict()\n",
    "sma18p = dict()\n",
    "for el in smb18:\n",
    "    smb18p[el] = round(len(smb18[el])*100/totartb18, 5)\n",
    "for el in sma18:\n",
    "    sma18p[el] = round(len(sma18[el])*100/totarta18, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "833bf5e6-c1d2-437d-868d-682a8219bb85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8460370204873723"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example data\n",
    "\n",
    "# Mean difference\n",
    "mean_diff = {key: sma18p[key] - smb18p[key] for key in smb18p}\n",
    "\n",
    "# Euclidean Distance\n",
    "euclidean_distance = sum((sma18p[key] - smb18p[key])**2 for key in smb18p)**0.5\n",
    "\n",
    "# Manhattan Distance\n",
    "manhattan_distance = sum(abs(sma18p[key] - smb18p[key]) for key in smb18p)\n",
    "\n",
    "# Cosine Similarity\n",
    "dot_product = sum(sma18p[key] * smb18p[key] for key in smb18p)\n",
    "magnitude_sma18p = sum(value**2 for value in sma18p.values())**0.5\n",
    "magnitude_smb18p = sum(value**2 for value in smb18p.values())**0.5\n",
    "cosine_similarity = dot_product / (magnitude_sma18p * magnitude_smb18p)\n",
    "\n",
    "# Correlation Coefficient\n",
    "import numpy as np\n",
    "smb18p_values = np.array(list(smb18p.values()))\n",
    "sma18p_values = np.array(list(sma18p.values()))\n",
    "correlation_coefficient = np.corrcoef(smb18p_values, sma18p_values)[0, 1]\n",
    "\n",
    "#mean_diff\n",
    "correlation_coefficient\n",
    "## In the paper we report the correlation_coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fc2407-300e-4f01-9822-020de3e2ca17",
   "metadata": {},
   "source": [
    "#### Correlation Flower Language Wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f083269a-d674-459d-b042-bcd93105ec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "art_before_1600 = list(before_1600[\"painting\"])\n",
    "art_between_1600_and_1699 = list(between_1600_and_1699[\"painting\"])\n",
    "art_between_1700_and_1799 = list(between_1700_and_1799[\"painting\"])\n",
    "art_between_1800_and_1899 = list(between_1800_and_1899[\"painting\"])\n",
    "art_after_1900 = list(after_1900[\"painting\"])\n",
    "periods = [art_before_1600,\n",
    "art_between_1600_and_1699,\n",
    "art_between_1700_and_1799,\n",
    "art_between_1800_and_1899,\n",
    "art_after_1900]\n",
    "symb_meanings_16th_century = dict()\n",
    "symb_meanings_17th_century = dict()\n",
    "symb_meanings_18th_century = dict()\n",
    "symb_meanings_19th_century = dict()\n",
    "symb_meanings_20_21th_century = dict()\n",
    "dizz_sm = [symb_meanings_16th_century,\n",
    "symb_meanings_17th_century,\n",
    "symb_meanings_18th_century,\n",
    "symb_meanings_19th_century,\n",
    "symb_meanings_20_21th_century]\n",
    "for i in range(len(dizz_sm)):    \n",
    "    for t in depi_simu:\n",
    "        for depi in depi_simu[t]:\n",
    "            for ctx in depi_simu[t][depi]:\n",
    "                if \"flowerLanguage\" in ctx:\n",
    "                    for meaning in depi_simu[t][depi][ctx]:\n",
    "                        meaning_short = meaning.split(hrdata)[1]\n",
    "                        if meaning_short not in dizz_sm[i]:\n",
    "                            dizz_sm[i][meaning_short] = set()\n",
    "                        for art in depi_simu[t][depi][\"artworks\"]:\n",
    "                            if art in periods[i]:\n",
    "                                dizz_sm[i][meaning_short].add(art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "10f7e595-b95b-4ad8-b760-2217e3339e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "smb18 = dict()\n",
    "for k in symb_meanings_16th_century:\n",
    "    if k not in smb18:\n",
    "        smb18[k] = symb_meanings_16th_century[k]\n",
    "    else:\n",
    "        smb18[k] = smb18[k].union(symb_meanings_16th_century[k])\n",
    "for k in symb_meanings_17th_century:\n",
    "    if k not in smb18:\n",
    "        smb18[k] = symb_meanings_17th_century[k]\n",
    "    else:\n",
    "        smb18[k] = smb18[k].union(symb_meanings_17th_century[k])\n",
    "for k in symb_meanings_18th_century:\n",
    "    if k not in smb18:\n",
    "        smb18[k] = symb_meanings_18th_century[k]\n",
    "    else:\n",
    "        smb18[k] = smb18[k].union(symb_meanings_18th_century[k])\n",
    "\n",
    "\n",
    "sma18 = dict()\n",
    "a18 = [symb_meanings_19th_century, symb_meanings_20_21th_century]\n",
    "for diz in a18: \n",
    "    for k in diz:\n",
    "        if k not in sma18:\n",
    "            sma18[k] = diz[k]\n",
    "        else:\n",
    "            sma18[k] = sma18[k].union(diz[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "22ac2648-5e18-46c5-9ffe-0a09d401b058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "655"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_art_fl_b = set()\n",
    "for el in smb18:\n",
    "    for art in smb18[el]:\n",
    "        total_art_fl_b.add(art)\n",
    "len(total_art_fl_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d1987969-fdb6-476c-962c-b2a1150a6789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_art_fl_a = set()\n",
    "for el in sma18:\n",
    "    for art in sma18[el]:\n",
    "        total_art_fl_a.add(art)\n",
    "len(total_art_fl_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "55125501-268d-46b6-a4cb-26da26d3834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "smb18p = dict()\n",
    "sma18p = dict()\n",
    "for el in smb18:\n",
    "    smb18p[el] = round(len(smb18[el])*100/655, 5)\n",
    "for el in sma18:\n",
    "    sma18p[el] = round(len(sma18[el])*100/332, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b6dd57c0-9b88-4211-be84-6f144938d152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6043809588229936"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example data\n",
    "\n",
    "# Mean difference\n",
    "mean_diff = {key: sma18p[key] - smb18p[key] for key in smb18p}\n",
    "\n",
    "# Euclidean Distance\n",
    "euclidean_distance = sum((sma18p[key] - smb18p[key])**2 for key in smb18p)**0.5\n",
    "\n",
    "# Manhattan Distance\n",
    "manhattan_distance = sum(abs(sma18p[key] - smb18p[key]) for key in smb18p)\n",
    "\n",
    "# Cosine Similarity\n",
    "dot_product = sum(sma18p[key] * smb18p[key] for key in smb18p)\n",
    "magnitude_sma18p = sum(value**2 for value in sma18p.values())**0.5\n",
    "magnitude_smb18p = sum(value**2 for value in smb18p.values())**0.5\n",
    "cosine_similarity = dot_product / (magnitude_sma18p * magnitude_smb18p)\n",
    "\n",
    "# Correlation Coefficient\n",
    "import numpy as np\n",
    "smb18p_values = np.array(list(smb18p.values()))\n",
    "sma18p_values = np.array(list(sma18p.values()))\n",
    "correlation_coefficient = np.corrcoef(smb18p_values, sma18p_values)[0, 1]\n",
    "\n",
    "#mean_diff\n",
    "correlation_coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317e2c48-90bd-414b-9406-86b45774150d",
   "metadata": {},
   "source": [
    "### Timesplit and correlation ODOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bae44462-a13c-497a-9afb-4f1e5a94f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_smelly_df['Earliest Date'] = pd.to_numeric(filtered_smelly_df['Earliest Date'], errors='coerce').astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5885dccb-542b-47e6-b3ae-3f8971eb9efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "smelly_after_1800 = filtered_smelly_df[filtered_smelly_df['Earliest Date'] > 1799]\n",
    "smelly_before_1800 = filtered_smelly_df[filtered_smelly_df['Earliest Date'] <= 1799]\n",
    "smelly_before_1800 = smelly_before_1800.reset_index()\n",
    "smelly_after_1800 = smelly_after_1800.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "18d3993e-6ef9-496b-a5cd-66fcc0388f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>File Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>Iconography</th>\n",
       "      <th>Earliest Date</th>\n",
       "      <th>Latest Date</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Material</th>\n",
       "      <th>Photo Archive</th>\n",
       "      <th>Image Credits</th>\n",
       "      <th>Details URL</th>\n",
       "      <th>Additional Information</th>\n",
       "      <th>Iconclass code</th>\n",
       "      <th>License</th>\n",
       "      <th>Description</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Language</th>\n",
       "      <th>detections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>d32c384a-256c-db74-5d6b-032d586fe79a.jpg</td>\n",
       "      <td>Otto B. de Kat</td>\n",
       "      <td>Stilleven met kannen en een schaal met fruit</td>\n",
       "      <td>Pomander</td>\n",
       "      <td>1950</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>painting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://rkd.nl/en/</td>\n",
       "      <td>https://images.rkd.nl/rkd/thumb/650x650/d32c38...</td>\n",
       "      <td>https://rkd.nl/explore/images/63054</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>still life,ewer (vessel),coffeepot,pipe,dish (...</td>\n",
       "      <td>en</td>\n",
       "      <td>fruit, carafe, pipe, drinking vessel, fig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>127</td>\n",
       "      <td>05b7974f-88a9-f82b-307f-6624952ff6c1.jpg</td>\n",
       "      <td>Otto B. de Kat</td>\n",
       "      <td>De koffiekan</td>\n",
       "      <td>Pomander</td>\n",
       "      <td>1972</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>painting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://rkd.nl/en/</td>\n",
       "      <td>https://images.rkd.nl/rkd/thumb/650x650/05b797...</td>\n",
       "      <td>https://rkd.nl/explore/images/111515</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>still life,coffeepot,dish (vessel for food)</td>\n",
       "      <td>en</td>\n",
       "      <td>coffeepot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>135</td>\n",
       "      <td>ee6f2a4c-24b6-85fc-1878-921b951d754e.jpg</td>\n",
       "      <td>Otto B. de Kat</td>\n",
       "      <td>Stilleven met koffiepot</td>\n",
       "      <td>Pomander</td>\n",
       "      <td>1982</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>painting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://rkd.nl/en/</td>\n",
       "      <td>https://images.rkd.nl/rkd/thumb/650x650/ee6f2a...</td>\n",
       "      <td>https://rkd.nl/explore/images/65510</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>still life,coffeepot</td>\n",
       "      <td>en</td>\n",
       "      <td>coffeepot, drinking vessel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>137</td>\n",
       "      <td>ec7b4dd4-b60c-6e63-102a-3f329cf68da5.jpg</td>\n",
       "      <td>Otto B. de Kat</td>\n",
       "      <td>Stilleven met koffiepot en Spaanse schotel</td>\n",
       "      <td>Pomander</td>\n",
       "      <td>1982</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>painting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://rkd.nl/en/</td>\n",
       "      <td>https://images.rkd.nl/rkd/thumb/650x650/ec7b4d...</td>\n",
       "      <td>https://rkd.nl/explore/images/65505</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>still life,coffeepot</td>\n",
       "      <td>en</td>\n",
       "      <td>flower, pot, coffeepot, lemon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>140</td>\n",
       "      <td>2461b83e-5aeb-3bfd-c5d0-fba832154f4a.jpg</td>\n",
       "      <td>Lou Meyboom</td>\n",
       "      <td>Still life with jug, vase, onion and thistle</td>\n",
       "      <td>Pomander</td>\n",
       "      <td>1896</td>\n",
       "      <td>1896.0</td>\n",
       "      <td>drawing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://rkd.nl/en/</td>\n",
       "      <td>https://images.rkd.nl/rkd/thumb/650x650/2461b8...</td>\n",
       "      <td>https://rkd.nl/explore/images/214004</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kitchen piece (still life),onion,coffeepot,vas...</td>\n",
       "      <td>en</td>\n",
       "      <td>coffeepot, onion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index                                 File Name            Artist  \\\n",
       "0        0    123  d32c384a-256c-db74-5d6b-032d586fe79a.jpg   Otto B. de Kat    \n",
       "1        2    127  05b7974f-88a9-f82b-307f-6624952ff6c1.jpg   Otto B. de Kat    \n",
       "2        4    135  ee6f2a4c-24b6-85fc-1878-921b951d754e.jpg   Otto B. de Kat    \n",
       "3        5    137  ec7b4dd4-b60c-6e63-102a-3f329cf68da5.jpg   Otto B. de Kat    \n",
       "4        6    140  2461b83e-5aeb-3bfd-c5d0-fba832154f4a.jpg      Lou Meyboom    \n",
       "\n",
       "                                            Title Iconography  Earliest Date  \\\n",
       "0   Stilleven met kannen en een schaal met fruit     Pomander           1950   \n",
       "1                                   De koffiekan     Pomander           1972   \n",
       "2                        Stilleven met koffiepot     Pomander           1982   \n",
       "3     Stilleven met koffiepot en Spaanse schotel     Pomander           1982   \n",
       "4   Still life with jug, vase, onion and thistle     Pomander           1896   \n",
       "\n",
       "   Latest Date     Genre Material       Photo Archive  \\\n",
       "0       1949.0  painting      NaN  https://rkd.nl/en/   \n",
       "1       1972.0  painting      NaN  https://rkd.nl/en/   \n",
       "2       1982.0  painting      NaN  https://rkd.nl/en/   \n",
       "3       1982.0  painting      NaN  https://rkd.nl/en/   \n",
       "4       1896.0   drawing      NaN  https://rkd.nl/en/   \n",
       "\n",
       "                                       Image Credits  \\\n",
       "0  https://images.rkd.nl/rkd/thumb/650x650/d32c38...   \n",
       "1  https://images.rkd.nl/rkd/thumb/650x650/05b797...   \n",
       "2  https://images.rkd.nl/rkd/thumb/650x650/ee6f2a...   \n",
       "3  https://images.rkd.nl/rkd/thumb/650x650/ec7b4d...   \n",
       "4  https://images.rkd.nl/rkd/thumb/650x650/2461b8...   \n",
       "\n",
       "                            Details URL Additional Information Iconclass code  \\\n",
       "0   https://rkd.nl/explore/images/63054                                   NaN   \n",
       "1  https://rkd.nl/explore/images/111515                                   NaN   \n",
       "2   https://rkd.nl/explore/images/65510                                   NaN   \n",
       "3   https://rkd.nl/explore/images/65505                                   NaN   \n",
       "4  https://rkd.nl/explore/images/214004                                   NaN   \n",
       "\n",
       "  License Description                                           Keywords  \\\n",
       "0     NaN         NaN  still life,ewer (vessel),coffeepot,pipe,dish (...   \n",
       "1     NaN         NaN       still life,coffeepot,dish (vessel for food)    \n",
       "2     NaN         NaN                              still life,coffeepot    \n",
       "3     NaN         NaN                              still life,coffeepot    \n",
       "4     NaN         NaN  kitchen piece (still life),onion,coffeepot,vas...   \n",
       "\n",
       "  Language                                 detections  \n",
       "0       en  fruit, carafe, pipe, drinking vessel, fig  \n",
       "1       en                                  coffeepot  \n",
       "2       en                 coffeepot, drinking vessel  \n",
       "3       en              flower, pot, coffeepot, lemon  \n",
       "4       en                           coffeepot, onion  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smelly_after_1800.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7c1caac1-76ac-47aa-b7d7-491446316bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "art_smelly_before_1800 = set(smelly_before_1800[\"File Name\"])\n",
    "art_smelly_after_1800 = set(smelly_after_1800[\"File Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3f5eafcf-4fbc-4861-9513-3acf253723aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(art_smelly_after_1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "af98b99d-bff7-4172-8d29-3641a372f48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symb_art_smelly = set()\n",
    "for t in depi_smelly_simu:\n",
    "    for symb in depi_smelly_simu[t]:\n",
    "        for art in depi_smelly_simu[t][symb][\"artworks\"]:\n",
    "            symb_art_smelly.add(art)\n",
    "len(symb_art_smelly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "86a01183-da1d-44a8-9f7b-de411cce3776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "439"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art_smelly_before_1800 = set([art for art in art_smelly_before_1800 if art in symb_art_smelly])\n",
    "len(art_smelly_before_1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a3df4645-0a27-4ded-86bf-c446f7b2ead7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art_smelly_after_1800 = set([art for art in art_smelly_after_1800 if art in symb_art_smelly])\n",
    "len(art_smelly_after_1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1a583ab9-2ece-4add-94f0-2563c945840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssmb18p = dict()\n",
    "ssma18p = dict()\n",
    "for t in depi_smelly_simu:\n",
    "    for symb in depi_smelly_simu[t]:\n",
    "        for ctx in depi_smelly_simu[t][symb]:\n",
    "            if ctx != \"artworks\":\n",
    "                for symb_meaning in depi_smelly_simu[t][symb][ctx]:\n",
    "                    if symb_meaning not in ssmb18p:\n",
    "                        ssmb18p[symb_meaning] = set()\n",
    "                    if symb_meaning not in ssma18p:\n",
    "                        ssma18p[symb_meaning] = set()\n",
    "                    for art in depi_smelly_simu[t][symb][\"artworks\"]:\n",
    "                        if art in art_smelly_before_1800:\n",
    "                            ssmb18p[symb_meaning].add(art)\n",
    "                        elif art in art_smelly_after_1800:\n",
    "                            ssma18p[symb_meaning].add(art)\n",
    "for el in ssmb18p:\n",
    "    ssmb18p[el] = len(ssmb18p[el])*100/439\n",
    "for el in ssma18p:\n",
    "    ssma18p[el] = len(ssma18p[el])*100/38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "46cc188f-d214-4d7d-8284-b5499d735a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.820024497113556"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example data\n",
    "\n",
    "# Mean difference\n",
    "mean_diff = {key: ssma18p[key] - ssmb18p[key] for key in ssmb18p}\n",
    "\n",
    "# Euclidean Distance\n",
    "euclidean_distance = sum((ssma18p[key] - ssmb18p[key])**2 for key in ssmb18p)**0.5\n",
    "\n",
    "# Manhattan Distance\n",
    "manhattan_distance = sum(abs(ssma18p[key] - ssmb18p[key]) for key in ssmb18p)\n",
    "\n",
    "# Cosine Similarity\n",
    "dot_product = sum(ssma18p[key] * ssmb18p[key] for key in ssmb18p)\n",
    "magnitude_sma18p = sum(value**2 for value in ssma18p.values())**0.5\n",
    "magnitude_smb18p = sum(value**2 for value in ssmb18p.values())**0.5\n",
    "cosine_similarity = dot_product / (magnitude_sma18p * magnitude_smb18p)\n",
    "\n",
    "# Correlation Coefficient\n",
    "import numpy as np\n",
    "smb18p_values = np.array(list(ssmb18p.values()))\n",
    "sma18p_values = np.array(list(ssma18p.values()))\n",
    "correlation_coefficient = np.corrcoef(smb18p_values, sma18p_values)[0, 1]\n",
    "\n",
    "#mean_diff\n",
    "correlation_coefficient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e065fb-f44d-4035-ba57-e01ca4f43a61",
   "metadata": {},
   "source": [
    "#### Correlation ODOR Flower Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "822e3839-7229-4dc6-a1d8-8f669f322657",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssmb18p = dict()\n",
    "ssma18p = dict()\n",
    "for t in depi_smelly_simu:\n",
    "    for symb in depi_smelly_simu[t]:\n",
    "        for ctx in depi_smelly_simu[t][symb]:\n",
    "            if \"flowerLanguage\" in ctx:\n",
    "                for symb_meaning in depi_smelly_simu[t][symb][ctx]:\n",
    "                    if symb_meaning not in ssmb18p:\n",
    "                        ssmb18p[symb_meaning] = set()\n",
    "                    if symb_meaning not in ssma18p:\n",
    "                        ssma18p[symb_meaning] = set()\n",
    "                    for art in depi_smelly_simu[t][symb][\"artworks\"]:\n",
    "                        if art in art_smelly_before_1800:\n",
    "                            ssmb18p[symb_meaning].add(art)\n",
    "                        elif art in art_smelly_after_1800:\n",
    "                            ssma18p[symb_meaning].add(art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "48db0747-2158-4b26-8ea6-906b584c201c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "art_fl_b18 = set()\n",
    "art_fl_a18 = set()\n",
    "for el in ssmb18p:\n",
    "    for art in ssmb18p[el]:\n",
    "        art_fl_b18.add(art)\n",
    "for el in ssma18p:\n",
    "    for art in ssma18p[el]:\n",
    "        art_fl_a18.add(art)\n",
    "print(len(art_fl_b18))\n",
    "print(len(art_fl_a18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dad6a581-5fb8-4f13-bc40-8b48155d48fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in ssmb18p:\n",
    "    ssmb18p[el] = len(ssmb18p[el])*100/226\n",
    "for el in ssma18p:\n",
    "    ssma18p[el] = len(ssma18p[el])*100/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "09611568-20c6-4d11-a321-2e527d0d4d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6198838691020041"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example data\n",
    "\n",
    "# Mean difference\n",
    "mean_diff = {key: ssma18p[key] - ssmb18p[key] for key in ssmb18p}\n",
    "\n",
    "# Euclidean Distance\n",
    "euclidean_distance = sum((ssma18p[key] - ssmb18p[key])**2 for key in ssmb18p)**0.5\n",
    "\n",
    "# Manhattan Distance\n",
    "manhattan_distance = sum(abs(ssma18p[key] - ssmb18p[key]) for key in ssmb18p)\n",
    "\n",
    "# Cosine Similarity\n",
    "dot_product = sum(ssma18p[key] * ssmb18p[key] for key in ssmb18p)\n",
    "magnitude_sma18p = sum(value**2 for value in ssma18p.values())**0.5\n",
    "magnitude_smb18p = sum(value**2 for value in ssmb18p.values())**0.5\n",
    "cosine_similarity = dot_product / (magnitude_sma18p * magnitude_smb18p)\n",
    "\n",
    "# Correlation Coefficient\n",
    "import numpy as np\n",
    "smb18p_values = np.array(list(ssmb18p.values()))\n",
    "sma18p_values = np.array(list(ssma18p.values()))\n",
    "correlation_coefficient = np.corrcoef(smb18p_values, sma18p_values)[0, 1]\n",
    "\n",
    "#mean_diff\n",
    "correlation_coefficient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924302e9-474b-49a5-9625-9cb89a7f527e",
   "metadata": {},
   "source": [
    "### Increased perc in symbolic meanings flower language context Wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dd1c12aa-23be-4ac7-8b23-559fa1875c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_before = pd.DataFrame(list(smb18p.items()), columns=['symbolic_meaning', 'before_1800'])\n",
    "df_after = pd.DataFrame(list(sma18p.items()), columns=['symbolic_meaning', 'after_1800'])\n",
    "\n",
    "# Merge DataFrames\n",
    "df_combined = pd.merge(df_before, df_after, on='symbolic_meaning', how='outer').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cbb41c68-a5e4-42ab-94de-31c748082dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affection\n",
      "increased perc\n",
      "7.45563\n",
      "percentage after 1800\n",
      "12.95181\n",
      "percentage before 1800\n",
      "5.49618\n",
      "***\n",
      "comfort\n",
      "increased perc\n",
      "7.45563\n",
      "percentage after 1800\n",
      "12.95181\n",
      "percentage before 1800\n",
      "5.49618\n",
      "***\n",
      "beauty\n",
      "increased perc\n",
      "12.34894\n",
      "percentage after 1800\n",
      "23.49398\n",
      "percentage before 1800\n",
      "11.14504\n",
      "***\n",
      "love\n",
      "increased perc\n",
      "12.34894\n",
      "percentage after 1800\n",
      "23.49398\n",
      "percentage before 1800\n",
      "11.14504\n",
      "***\n",
      "gallantry\n",
      "increased perc\n",
      "8.895430000000001\n",
      "percentage after 1800\n",
      "19.27711\n",
      "percentage before 1800\n",
      "10.38168\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "# Make sure you run this after you have run the correlation FL in Wikidata\n",
    "for i in range(len(df_combined[\"symbolic_meaning\"])):\n",
    "    if df_combined[\"before_1800\"][i] < df_combined[\"after_1800\"][i]:\n",
    "        if df_combined[\"after_1800\"][i] - df_combined[\"before_1800\"][i] > 7:\n",
    "            print(df_combined[\"symbolic_meaning\"][i])\n",
    "            print(\"increased perc\")\n",
    "            print(df_combined[\"after_1800\"][i] - df_combined[\"before_1800\"][i])\n",
    "            print(\"percentage after 1800\")\n",
    "            print(df_combined[\"after_1800\"][i])\n",
    "            print(\"percentage before 1800\")\n",
    "            print(df_combined[\"before_1800\"][i])\n",
    "            print(\"***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991a711e-67c1-45ec-9c7e-25b8b0fed136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
